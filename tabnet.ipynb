{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagas\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.08834 | val_accuracy: 0.94242 |  0:08:06s\n",
      "epoch 10 | loss: 0.06061 | val_accuracy: 0.9874  |  1:30:28s\n",
      "epoch 20 | loss: 0.05609 | val_accuracy: 0.98772 |  2:42:12s\n",
      "epoch 30 | loss: 0.05419 | val_accuracy: 0.98806 |  8:54:23s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_accuracy = 0.98811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagas\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9876    0.9996    0.9936    674549\n",
      "           1     0.9948    0.8587    0.9217     59882\n",
      "\n",
      "    accuracy                         0.9881    734431\n",
      "   macro avg     0.9912    0.9292    0.9577    734431\n",
      "weighted avg     0.9882    0.9881    0.9877    734431\n",
      "\n",
      "Confusion Matrix:\n",
      "[[674278    271]\n",
      " [  8460  51422]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagas\\AppData\\Local\\Temp\\ipykernel_27684\\4080533000.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[features] = scaler.transform(X_test[features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.9995    0.9847   3358210\n",
      "           1     0.9940    0.7395    0.8480    393836\n",
      "\n",
      "    accuracy                         0.9722   3752046\n",
      "   macro avg     0.9822    0.8695    0.9164   3752046\n",
      "weighted avg     0.9728    0.9722    0.9703   3752046\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3356450    1760]\n",
      " [ 102612  291224]]\n"
     ]
    }
   ],
   "source": [
    "# tabnet_can.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "\n",
    "# --------------------------\n",
    "# Reproducibility\n",
    "# --------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ==========================\n",
    "# Feature Engineering\n",
    "# ==========================\n",
    "def safe_hex_to_int(x):\n",
    "    try:\n",
    "        return int(str(x), 16)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['CAN_ID_numeric'] = df.get('CAN_ID_hex', 0).apply(safe_hex_to_int)\n",
    "\n",
    "    # Normalize Data_hex\n",
    "    df['Data_clean'] = df.get('Data_hex', '').fillna('').astype(str).str.replace(' ', '')\n",
    "    df['Data_clean'] = df['Data_clean'].apply(lambda s: (s + '0'*16)[:16])\n",
    "\n",
    "    for i in range(8):\n",
    "        df[f'Byte_{i}'] = df['Data_clean'].apply(\n",
    "            lambda x: int(x[i*2:(i+1)*2], 16) if len(x) >= (i+1)*2 else 0\n",
    "        )\n",
    "\n",
    "    byte_cols = [f'Byte_{i}' for i in range(8)]\n",
    "    df['Data_mean'] = df[byte_cols].mean(axis=1)\n",
    "    df['Data_std'] = df[byte_cols].std(axis=1).fillna(0)\n",
    "    df['Data_sum'] = df[byte_cols].sum(axis=1)\n",
    "\n",
    "    if 'DLC' in df.columns:\n",
    "        df['DLC_cat'] = LabelEncoder().fit_transform(df['DLC'].astype(str))\n",
    "    else:\n",
    "        df['DLC_cat'] = 0\n",
    "\n",
    "    df['CAN_Priority'] = pd.cut(df['CAN_ID_numeric'],\n",
    "                                bins=[-1, 255, 1023, np.inf],\n",
    "                                labels=[0, 1, 2]).astype(int)\n",
    "    return df\n",
    "\n",
    "# ==========================\n",
    "# Main pipeline\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Training files\n",
    "    train_files = [\n",
    "        \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_1.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_2.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_1.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_2.csv\"\n",
    "    ]\n",
    "\n",
    "    test_files = [\n",
    "        \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/1_Submission/Pre_submit_D.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/1_Submission/Pre_submit_S.csv\"\n",
    "]\n",
    "\n",
    "    # ---------- load training data ----------\n",
    "    train_df = pd.concat([pd.read_csv(f) for f in train_files], ignore_index=True)\n",
    "    train_df.rename(columns={'Arbitration_ID': 'CAN_ID_hex', 'Data': 'Data_hex'}, inplace=True)\n",
    "    train_df = create_features(train_df)\n",
    "\n",
    "    # ---------- binary labels ----------\n",
    "    if 'Class' in train_df.columns:\n",
    "        if 'R' in train_df['Class'].values:\n",
    "            train_df['Binary_Label'] = train_df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "        elif 'Attack' in train_df['Class'].values:\n",
    "            train_df['Binary_Label'] = train_df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "        else:\n",
    "            train_df['Binary_Label'] = train_df['Class'].apply(lambda x: 0 if str(x).lower() == 'normal' else 1)\n",
    "    elif 'SubClass' in train_df.columns:\n",
    "        train_df['Binary_Label'] = train_df['SubClass'].apply(lambda x: 0 if pd.isna(x) or str(x).lower() == 'normal' else 1)\n",
    "    else:\n",
    "        train_df['Binary_Label'] = np.random.choice([0, 1], size=len(train_df), p=[0.7, 0.3])\n",
    "\n",
    "    features = ['CAN_ID_numeric', 'Data_mean', 'Data_std', 'Data_sum'] + \\\n",
    "               [f'Byte_{i}' for i in range(8)] + ['DLC_cat', 'CAN_Priority']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_df[features], train_df['Binary_Label'],\n",
    "        test_size=0.2, stratify=train_df['Binary_Label'], random_state=42\n",
    "    )\n",
    "\n",
    "    # scale continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train[features] = scaler.fit_transform(X_train[features])\n",
    "    X_val[features] = scaler.transform(X_val[features])\n",
    "\n",
    "    # TabNet expects numpy\n",
    "    X_train_np, y_train_np = X_train.values, y_train.values\n",
    "    X_val_np, y_val_np = X_val.values, y_val.values\n",
    "\n",
    "    # ---------- train TabNet ----------\n",
    "    clf = TabNetClassifier(\n",
    "        n_d=64, n_a=64, n_steps=5,\n",
    "        gamma=1.5, n_independent=2, n_shared=2,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-3),\n",
    "        scheduler_params={\"step_size\":20, \"gamma\":0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type=\"entmax\",  # \"sparsemax\" also works\n",
    "        verbose=10,\n",
    "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=X_train_np, y_train=y_train_np,\n",
    "        eval_set=[(X_val_np, y_val_np)],\n",
    "        eval_name=[\"val\"],\n",
    "        eval_metric=[\"accuracy\"],\n",
    "        max_epochs=50, patience=10,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0, drop_last=False\n",
    "    )\n",
    "\n",
    "    # ---------- validation report ----------\n",
    "    val_preds = clf.predict(X_val_np)\n",
    "    print(\"\\nValidation Report:\")\n",
    "    print(classification_report(y_val_np, val_preds, digits=4))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val_np, val_preds))\n",
    "\n",
    "    # ---------- test ----------\n",
    "    test_df = pd.concat([pd.read_csv(f) for f in test_files], ignore_index=True)\n",
    "    test_df.rename(columns={'Arbitration_ID': 'CAN_ID_hex', 'Data': 'Data_hex'}, inplace=True)\n",
    "    test_df = create_features(test_df)\n",
    "\n",
    "    if 'Class' in test_df.columns:\n",
    "        if 'R' in test_df['Class'].values:\n",
    "            test_df['Binary_Label'] = test_df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "        elif 'Attack' in test_df['Class'].values:\n",
    "            test_df['Binary_Label'] = test_df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "        else:\n",
    "            test_df['Binary_Label'] = test_df['Class'].apply(lambda x: 0 if str(x).lower() == 'normal' else 1)\n",
    "        labels_exist = True\n",
    "    else:\n",
    "        test_df['Binary_Label'] = np.zeros(len(test_df), dtype=int)\n",
    "        labels_exist = False\n",
    "\n",
    "    X_test, y_test = test_df[features], test_df['Binary_Label']\n",
    "    X_test[features] = scaler.transform(X_test[features])\n",
    "    X_test_np, y_test_np = X_test.values, y_test.values\n",
    "\n",
    "    preds_test = clf.predict(X_test_np)\n",
    "\n",
    "    if labels_exist:\n",
    "        print(\"\\nTest Report:\")\n",
    "        print(classification_report(y_test_np, preds_test, digits=4))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test_np, preds_test))\n",
    "    else:\n",
    "        print(\"Test predictions (no labels available):\", preds_test[:20])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
