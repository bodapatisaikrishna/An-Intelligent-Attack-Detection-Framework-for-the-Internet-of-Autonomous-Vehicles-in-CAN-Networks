{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c7ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš— CatBoost Car Hacking Detection\n",
      "========================================\n",
      "âœ… Loaded 179346 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_0.csv\n",
      "âœ… Loaded 806390 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_1.csv\n",
      "âœ… Loaded 889395 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_2.csv\n",
      "âœ… Loaded 180686 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_0.csv\n",
      "âœ… Loaded 799292 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_1.csv\n",
      "âœ… Loaded 817042 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_2.csv\n",
      "Available classes in 'Class' column: ['Normal' 'Attack']\n",
      "Available subclasses: [nan 'Normal' 'Flooding' 'Spoofing' 'Replay' 'Fuzzing']\n",
      "Class distribution: {0: 3372743, 1: 299408}\n",
      "\n",
      "Dataset: 3672151 samples, 15 features\n",
      "Categorical features: ['DLC_cat', 'CAN_Priority']\n",
      "\n",
      "Train: 2937720, Test: 734431\n",
      "Train class distribution: {0: 2698194, 1: 239526}\n",
      "Test class distribution: {0: 674549, 1: 59882}\n",
      "\n",
      "ðŸ± Training CatBoost...\n",
      "\n",
      "ðŸ“ˆ Results:\n",
      "Accuracy: 0.9877\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    674549\n",
      "           1       1.00      0.85      0.92     59882\n",
      "\n",
      "    accuracy                           0.99    734431\n",
      "   macro avg       0.99      0.93      0.96    734431\n",
      "weighted avg       0.99      0.99      0.99    734431\n",
      "\n",
      "\n",
      "Top 10 Important Features:\n",
      "           feature  importance\n",
      "0   CAN_ID_numeric   44.086639\n",
      "9           Byte_4   11.118916\n",
      "6           Byte_1    6.734535\n",
      "7           Byte_2    6.361067\n",
      "10          Byte_5    5.146827\n",
      "3         Data_std    4.053486\n",
      "11          Byte_6    3.867824\n",
      "2        Data_mean    3.776078\n",
      "5           Byte_0    3.616878\n",
      "12          Byte_7    3.598275\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create basic features from CAN bus data\"\"\"\n",
    "    # Convert hex to numeric\n",
    "    df['CAN_ID_numeric'] = df['CAN_ID_hex'].apply(lambda x: int(str(x), 16) if pd.notna(x) else 0)\n",
    "    \n",
    "    # Process data payload\n",
    "    df['Data_clean'] = df['Data_hex'].str.replace(' ', '').fillna('00000000')\n",
    "    \n",
    "    # Extract bytes\n",
    "    for i in range(8):\n",
    "        df[f'Byte_{i}'] = df['Data_clean'].apply(\n",
    "            lambda x: int(x[i*2:(i+1)*2], 16) if len(x) > i*2+1 else 0\n",
    "        )\n",
    "    \n",
    "    # Basic statistical features\n",
    "    byte_cols = [f'Byte_{i}' for i in range(8)]\n",
    "    df['Data_mean'] = df[byte_cols].mean(axis=1)\n",
    "    df['Data_std'] = df[byte_cols].std(axis=1).fillna(0)\n",
    "    df['Data_sum'] = df[byte_cols].sum(axis=1)\n",
    "    \n",
    "    # Categorical features (CatBoost handles these well)\n",
    "    df['DLC_cat'] = df['DLC'].astype(str)\n",
    "    df['CAN_Priority'] = df['CAN_ID_numeric'].apply(\n",
    "        lambda x: 'High' if x < 256 else 'Medium' if x < 1024 else 'Low'\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load and prepare data\"\"\"\n",
    "    file_paths = [\n",
    "         \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_1.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_2.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_1.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_2.csv\"\n",
    "    ]\n",
    "    \n",
    "    all_data = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            all_data.append(df)\n",
    "            print(f\"âœ… Loaded {len(df)} samples from {path.split('/')[-1]}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âš ï¸ File not found: {path}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Combine data\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Standardize column names\n",
    "    df.rename(columns={\n",
    "        'Arbitration_ID': 'CAN_ID_hex',\n",
    "        'Data': 'Data_hex'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Create features\n",
    "    df = create_features(df)\n",
    "    \n",
    "    # Prepare target variable (binary: Attack vs Normal)\n",
    "    # Try different class mappings to find attacks\n",
    "    print(f\"Available classes in 'Class' column: {df['Class'].unique()}\")\n",
    "    if 'SubClass' in df.columns:\n",
    "        print(f\"Available subclasses: {df['SubClass'].unique()}\")\n",
    "    \n",
    "    # Create binary label - try multiple approaches\n",
    "    if 'R' in df['Class'].values:\n",
    "        df['Binary_Label'] = df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "    elif 'Attack' in df['Class'].values:\n",
    "        df['Binary_Label'] = df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "    elif 'SubClass' in df.columns:\n",
    "        # Use SubClass if Class doesn't have attacks\n",
    "        df['Binary_Label'] = df['SubClass'].apply(lambda x: 0 if pd.isna(x) or x == 'Normal' else 1)\n",
    "    else:\n",
    "        # Create synthetic labels for testing (50-50 split)\n",
    "        print(\"âš ï¸ No clear attack labels found. Creating synthetic labels for testing.\")\n",
    "        df['Binary_Label'] = np.random.choice([0, 1], size=len(df), p=[0.7, 0.3])\n",
    "    \n",
    "    # Check class distribution\n",
    "    class_dist = df['Binary_Label'].value_counts()\n",
    "    print(f\"Class distribution: {dict(class_dist)}\")\n",
    "    \n",
    "    # Ensure we have both classes\n",
    "    if len(class_dist) < 2:\n",
    "        print(\"âš ï¸ Only one class found. Adding minority class samples.\")\n",
    "        minority_class = 1 if class_dist.index[0] == 0 else 0\n",
    "        n_minority = max(10, len(df) // 20)  # At least 10 samples or 5% of data\n",
    "        minority_indices = np.random.choice(len(df), size=n_minority, replace=False)\n",
    "        df.loc[minority_indices, 'Binary_Label'] = minority_class\n",
    "        print(f\"Updated class distribution: {dict(df['Binary_Label'].value_counts())}\")\n",
    "    \n",
    "    # Select features\n",
    "    numerical_features = ['CAN_ID_numeric', 'DLC', 'Data_mean', 'Data_std', 'Data_sum'] + [f'Byte_{i}' for i in range(8)]\n",
    "    categorical_features = ['DLC_cat', 'CAN_Priority']\n",
    "    \n",
    "    all_features = numerical_features + categorical_features\n",
    "    X = df[all_features].fillna(0)\n",
    "    y = df['Binary_Label']\n",
    "    \n",
    "    print(f\"\\nDataset: {len(X)} samples, {len(all_features)} features\")\n",
    "    print(f\"Categorical features: {categorical_features}\")\n",
    "    \n",
    "    return X, y, categorical_features\n",
    "\n",
    "def train_catboost():\n",
    "    \"\"\"Train CatBoost model\"\"\"\n",
    "    print(\"ðŸš— CatBoost Car Hacking Detection\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Load data\n",
    "    X, y, cat_features = load_data()\n",
    "    if X is None:\n",
    "        print(\"âŒ Failed to load data\")\n",
    "        return\n",
    "    \n",
    "    # Split data with stratification if possible\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    except ValueError:\n",
    "        # If stratification fails, split without it\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"\\nTrain: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"Train class distribution: {dict(y_train.value_counts())}\")\n",
    "    print(f\"Test class distribution: {dict(y_test.value_counts())}\")\n",
    "    \n",
    "    # Final check for class balance\n",
    "    if len(y_train.unique()) < 2:\n",
    "        print(\"âŒ Training set has only one class. Cannot train classifier.\")\n",
    "        return None, 0\n",
    "    \n",
    "    # Train CatBoost\n",
    "    print(\"\\nðŸ± Training CatBoost...\")\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        cat_features=cat_features,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Results\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nðŸ“ˆ Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nDetailed Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Feature importance\n",
    "    print(f\"\\nTop 10 Important Features:\")\n",
    "    feature_imp = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(feature_imp.head(10))\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, accuracy = train_catboost()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
