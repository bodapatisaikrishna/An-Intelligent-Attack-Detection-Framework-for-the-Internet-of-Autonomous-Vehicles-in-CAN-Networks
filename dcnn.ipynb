{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš— DCNN Car Hacking Detection\n",
      "========================================\n",
      "âœ… Loaded 179346 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_0.csv\n",
      "âœ… Loaded 806390 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_1.csv\n",
      "âœ… Loaded 889395 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_D_2.csv\n",
      "âœ… Loaded 180686 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_0.csv\n",
      "âœ… Loaded 799292 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_1.csv\n",
      "âœ… Loaded 817042 samples from C:\\Users\\nagas\\Downloads\\Car_Hacking_Challenge_Dataset_rev20Mar2021\\0_Preliminary\\0_Training\\Pre_train_S_2.csv\n",
      "Available classes in 'Class' column: ['Normal' 'Attack']\n",
      "Available subclasses: [nan 'Normal' 'Flooding' 'Spoofing' 'Replay' 'Fuzzing']\n",
      "Class distribution: {0: np.int64(3372743), 1: np.int64(299408)}\n",
      "\n",
      "Dataset: 3672151 samples, 8 features\n",
      "Normal (0): 3372743 (91.85%)\n",
      "Attack (1): 299408 (8.15%)\n",
      "\n",
      "Train: 2937720, Test: 734431\n",
      "Train class distribution: Normal=2698194, Attack=239526\n",
      "Test class distribution: Normal=674549, Attack=59882\n",
      "\n",
      "ğŸ—ï¸  Building DCNN model...\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DCNN_CAN_IDS\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DCNN_CAN_IDS\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn_input (\u001b[38;5;33mBatchNormalization\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           â”‚             \u001b[38;5;34m4\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1 (\u001b[38;5;33mConv1D\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ pool1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout1 (\u001b[38;5;33mDropout\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2 (\u001b[38;5;33mConv1D\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout2 (\u001b[38;5;33mDropout\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense1 (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m65,664\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout3 (\u001b[38;5;33mDropout\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense2 (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout4 (\u001b[38;5;33mDropout\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚           \u001b[38;5;34m130\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,782</span> (389.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,782\u001b[0m (389.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,396</span> (388.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,396\u001b[0m (388.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ Training DCNN...\n",
      "Epoch 1/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1311 - val_accuracy: 0.9606 - val_loss: 0.1083 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 8ms/step - accuracy: 0.9573 - loss: 0.1153 - val_accuracy: 0.9610 - val_loss: 0.1063 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 8ms/step - accuracy: 0.9590 - loss: 0.1119 - val_accuracy: 0.9636 - val_loss: 0.1029 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 8ms/step - accuracy: 0.9599 - loss: 0.1101 - val_accuracy: 0.9643 - val_loss: 0.1018 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 8ms/step - accuracy: 0.9605 - loss: 0.1091 - val_accuracy: 0.9643 - val_loss: 0.1016 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.1084 - val_accuracy: 0.9632 - val_loss: 0.1027 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 8ms/step - accuracy: 0.9612 - loss: 0.1079 - val_accuracy: 0.9641 - val_loss: 0.1006 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 8ms/step - accuracy: 0.9613 - loss: 0.1076 - val_accuracy: 0.9644 - val_loss: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.1072 - val_accuracy: 0.9647 - val_loss: 0.0986 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.1071 - val_accuracy: 0.9644 - val_loss: 0.0994 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.1071 - val_accuracy: 0.9642 - val_loss: 0.1003 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1072\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1073 - val_accuracy: 0.9643 - val_loss: 0.0996 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 9ms/step - accuracy: 0.9624 - loss: 0.1051 - val_accuracy: 0.9644 - val_loss: 0.0982 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 8ms/step - accuracy: 0.9625 - loss: 0.1050 - val_accuracy: 0.9644 - val_loss: 0.0994 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 8ms/step - accuracy: 0.9625 - loss: 0.1048 - val_accuracy: 0.9648 - val_loss: 0.0981 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9625 - loss: 0.1049\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 9ms/step - accuracy: 0.9625 - loss: 0.1048 - val_accuracy: 0.9647 - val_loss: 0.0985 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 9ms/step - accuracy: 0.9630 - loss: 0.1037 - val_accuracy: 0.9648 - val_loss: 0.0975 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 9ms/step - accuracy: 0.9629 - loss: 0.1037 - val_accuracy: 0.9647 - val_loss: 0.0978 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 10ms/step - accuracy: 0.9629 - loss: 0.1037 - val_accuracy: 0.9647 - val_loss: 0.0978 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9629 - loss: 0.1038\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 10ms/step - accuracy: 0.9629 - loss: 0.1037 - val_accuracy: 0.9646 - val_loss: 0.0978 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1031 - val_accuracy: 0.9648 - val_loss: 0.0975 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.1032 - val_accuracy: 0.9647 - val_loss: 0.0977 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.1032 - val_accuracy: 0.9648 - val_loss: 0.0972 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1030 - val_accuracy: 0.9648 - val_loss: 0.0971 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1032 - val_accuracy: 0.9648 - val_loss: 0.0973 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1031 - val_accuracy: 0.9648 - val_loss: 0.0970 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1029 - val_accuracy: 0.9647 - val_loss: 0.0976 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1030 - val_accuracy: 0.9648 - val_loss: 0.0970 - learning_rate: 1.2500e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m22949/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1031\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 9ms/step - accuracy: 0.9632 - loss: 0.1031 - val_accuracy: 0.9647 - val_loss: 0.0973 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m22951/22951\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 9ms/step - accuracy: 0.9633 - loss: 0.1027 - val_accuracy: 0.9648 - val_loss: 0.0970 - learning_rate: 6.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\n",
      "ğŸ“ˆ Results:\n",
      "Accuracy: 0.9648\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "            Normal  Attack\n",
      "Normal  [657,492  17,057]\n",
      "Attack  [  8,788  51,094]\n",
      "\n",
      "Detailed Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9868    0.9747    0.9807    674549\n",
      "      Attack     0.7497    0.8532    0.7981     59882\n",
      "\n",
      "    accuracy                         0.9648    734431\n",
      "   macro avg     0.8683    0.9140    0.8894    734431\n",
      "weighted avg     0.9675    0.9648    0.9658    734431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Model saved to: dcnn_car_hacking_model.h5\n",
      "\n",
      "ğŸ¯ Final Accuracy: 0.9648 (96.48%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.layers import Input, Conv1D, Flatten, Dense, Dropout, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create features from CAN bus data\"\"\"\n",
    "    # Convert hex to numeric\n",
    "    df['CAN_ID_numeric'] = df['CAN_ID_hex'].apply(lambda x: int(str(x), 16) if pd.notna(x) else 0)\n",
    "    \n",
    "    # Process data payload\n",
    "    df['Data_clean'] = df['Data_hex'].str.replace(' ', '').fillna('00000000')\n",
    "    \n",
    "    # Extract bytes\n",
    "    for i in range(8):\n",
    "        df[f'Byte_{i}'] = df['Data_clean'].apply(\n",
    "            lambda x: int(x[i*2:(i+1)*2], 16) if len(x) > i*2+1 else 0\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load and prepare data\"\"\"\n",
    "    file_paths = [\n",
    "        \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_1.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_2.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_1.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_2.csv\"\n",
    "    ]\n",
    "    all_data = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            all_data.append(df)\n",
    "            print(f\"âœ… Loaded {len(df)} samples from {path.split('/')[-1]}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âš ï¸ File not found: {path}\")\n",
    "    \n",
    "    if not all_data:\n",
    "        return None, None\n",
    "    \n",
    "    # Combine data\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Standardize column names\n",
    "    df.rename(columns={\n",
    "        'Arbitration_ID': 'CAN_ID_hex',\n",
    "        'Data': 'Data_hex'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Create features\n",
    "    df = create_features(df)\n",
    "    \n",
    "    # Prepare target variable (binary: Attack vs Normal)\n",
    "    print(f\"Available classes in 'Class' column: {df['Class'].unique()}\")\n",
    "    if 'SubClass' in df.columns:\n",
    "        print(f\"Available subclasses: {df['SubClass'].unique()}\")\n",
    "    \n",
    "    # Create binary label\n",
    "    if 'R' in df['Class'].values:\n",
    "        df['Binary_Label'] = df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "    elif 'Attack' in df['Class'].values:\n",
    "        df['Binary_Label'] = df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "    elif 'SubClass' in df.columns:\n",
    "        df['Binary_Label'] = df['SubClass'].apply(lambda x: 0 if pd.isna(x) or x == 'Normal' else 1)\n",
    "    else:\n",
    "        print(\"âš ï¸ No clear attack labels found. Creating synthetic labels for testing.\")\n",
    "        df['Binary_Label'] = np.random.choice([0, 1], size=len(df), p=[0.7, 0.3])\n",
    "    \n",
    "    # Check class distribution\n",
    "    class_dist = df['Binary_Label'].value_counts()\n",
    "    print(f\"Class distribution: {dict(class_dist)}\")\n",
    "    \n",
    "    # Ensure we have both classes\n",
    "    if len(class_dist) < 2:\n",
    "        print(\"âš ï¸ Only one class found. Adding minority class samples.\")\n",
    "        minority_class = 1 if class_dist.index[0] == 0 else 0\n",
    "        n_minority = max(10, len(df) // 20)\n",
    "        minority_indices = np.random.choice(len(df), size=n_minority, replace=False)\n",
    "        df.loc[minority_indices, 'Binary_Label'] = minority_class\n",
    "        print(f\"Updated class distribution: {dict(df['Binary_Label'].value_counts())}\")\n",
    "    \n",
    "    # Extract byte features for DCNN\n",
    "    byte_features = [f'Byte_{i}' for i in range(8)]\n",
    "    X = df[byte_features].fillna(0).values.astype(np.float32)\n",
    "    y = df['Binary_Label'].values.astype(np.int32)\n",
    "    \n",
    "    print(f\"\\nDataset: {len(X)} samples, {X.shape[1]} features\")\n",
    "    print(f\"Normal (0): {sum(y == 0)} ({sum(y == 0)/len(y)*100:.2f}%)\")\n",
    "    print(f\"Attack (1): {sum(y == 1)} ({sum(y == 1)/len(y)*100:.2f}%)\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def build_dcnn(input_shape):\n",
    "    \"\"\"Build Deep Convolutional Neural Network for CAN intrusion detection\"\"\"\n",
    "    inp = Input(shape=input_shape, name='input_layer')\n",
    "    \n",
    "    # Batch normalization for input\n",
    "    x = BatchNormalization(name='bn_input')(inp)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same', name='conv1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = MaxPooling1D(pool_size=2, name='pool1')(x)\n",
    "    x = Dropout(0.25, name='dropout1')(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Dropout(0.25, name='dropout2')(x)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(128, activation='relu', name='dense1')(x)\n",
    "    x = Dropout(0.4, name='dropout3')(x)\n",
    "    x = Dense(64, activation='relu', name='dense2')(x)\n",
    "    x = Dropout(0.3, name='dropout4')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    out = Dense(2, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out, name='DCNN_CAN_IDS')\n",
    "    \n",
    "    # Compile with optimizer\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_dcnn():\n",
    "    \"\"\"Train DCNN model\"\"\"\n",
    "    print(\"ğŸš— DCNN Car Hacking Detection\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Load data\n",
    "    X, y = load_data()\n",
    "    if X is None:\n",
    "        print(\"âŒ Failed to load data\")\n",
    "        return None, 0\n",
    "    \n",
    "    # Reshape for Conv1D: (samples, timesteps, features)\n",
    "    X = X.reshape(-1, 8, 1)\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_cat = to_categorical(y, num_classes=2)\n",
    "    \n",
    "    # Split data with stratification\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_cat, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_cat, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nTrain: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"Train class distribution: Normal={sum(np.argmax(y_train, axis=1) == 0)}, Attack={sum(np.argmax(y_train, axis=1) == 1)}\")\n",
    "    print(f\"Test class distribution: Normal={sum(np.argmax(y_test, axis=1) == 0)}, Attack={sum(np.argmax(y_test, axis=1) == 1)}\")\n",
    "    \n",
    "    # Final check for class balance\n",
    "    if len(np.unique(np.argmax(y_train, axis=1))) < 2:\n",
    "        print(\"âŒ Training set has only one class. Cannot train classifier.\")\n",
    "        return None, 0\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\nğŸ—ï¸  Building DCNN model...\")\n",
    "    model = build_dcnn((8, 1))\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nğŸ’¡ Training DCNN...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Results\n",
    "    accuracy = accuracy_score(y_test_label, y_pred)\n",
    "    print(f\"\\nğŸ“ˆ Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test_label, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"              Predicted\")\n",
    "    print(f\"            Normal  Attack\")\n",
    "    print(f\"Normal  [{cm[0][0]:7,d} {cm[0][1]:7,d}]\")\n",
    "    print(f\"Attack  [{cm[1][0]:7,d} {cm[1][1]:7,d}]\")\n",
    "    \n",
    "    print(f\"\\nDetailed Report:\")\n",
    "    print(classification_report(\n",
    "        y_test_label, y_pred,\n",
    "        target_names=['Normal', 'Attack'],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"dcnn_car_hacking_model.h5\"\n",
    "    model.save(model_path)\n",
    "    print(f\"\\nğŸ’¾ Model saved to: {model_path}\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, accuracy = train_dcnn()\n",
    "    \n",
    "    if model is not None:\n",
    "        print(f\"\\nğŸ¯ Final Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Training failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012009d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
