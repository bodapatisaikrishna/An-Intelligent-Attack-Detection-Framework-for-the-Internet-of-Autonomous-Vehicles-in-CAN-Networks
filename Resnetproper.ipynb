{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Val Accuracy: 0.9819\n",
      "Epoch 2/30 - Val Accuracy: 0.9825\n",
      "Epoch 3/30 - Val Accuracy: 0.9827\n",
      "Epoch 4/30 - Val Accuracy: 0.9806\n",
      "Epoch 5/30 - Val Accuracy: 0.9808\n",
      "Epoch 6/30 - Val Accuracy: 0.9789\n",
      "Epoch 7/30 - Val Accuracy: 0.9792\n",
      "Epoch 8/30 - Val Accuracy: 0.9839\n",
      "Epoch 9/30 - Val Accuracy: 0.9770\n",
      "Epoch 10/30 - Val Accuracy: 0.9816\n",
      "Epoch 11/30 - Val Accuracy: 0.9836\n",
      "Epoch 12/30 - Val Accuracy: 0.9812\n",
      "Epoch 13/30 - Val Accuracy: 0.9782\n",
      "Epoch 14/30 - Val Accuracy: 0.9804\n",
      "Epoch 15/30 - Val Accuracy: 0.9788\n",
      "Epoch 16/30 - Val Accuracy: 0.9808\n",
      "Epoch 17/30 - Val Accuracy: 0.9805\n",
      "Epoch 18/30 - Val Accuracy: 0.9816\n",
      "Epoch 19/30 - Val Accuracy: 0.9816\n",
      "Epoch 20/30 - Val Accuracy: 0.9800\n",
      "Epoch 21/30 - Val Accuracy: 0.9834\n",
      "Epoch 22/30 - Val Accuracy: 0.9816\n",
      "Epoch 23/30 - Val Accuracy: 0.9835\n",
      "Epoch 24/30 - Val Accuracy: 0.9788\n",
      "Epoch 25/30 - Val Accuracy: 0.9799\n",
      "Epoch 26/30 - Val Accuracy: 0.9819\n",
      "Epoch 27/30 - Val Accuracy: 0.9805\n",
      "Epoch 28/30 - Val Accuracy: 0.9804\n",
      "Epoch 29/30 - Val Accuracy: 0.9796\n",
      "Epoch 30/30 - Val Accuracy: 0.9807\n",
      "\n",
      "ðŸ“Š Final Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9900    0.9890    0.9895    674549\n",
      "           1     0.8776    0.8874    0.8825     59882\n",
      "\n",
      "    accuracy                         0.9807    734431\n",
      "   macro avg     0.9338    0.9382    0.9360    734431\n",
      "weighted avg     0.9808    0.9807    0.9808    734431\n",
      "\n",
      "\n",
      "ðŸ“Š Test Set Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9719    0.9891    0.9804   3358210\n",
      "           1     0.8902    0.7559    0.8175    393836\n",
      "\n",
      "    accuracy                         0.9646   3752046\n",
      "   macro avg     0.9310    0.8725    0.8990   3752046\n",
      "weighted avg     0.9633    0.9646    0.9633   3752046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# ResNet Implementation for Tabular CAN Data (Imbalance Handling + Test Evaluation)\n",
    "# ==================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==================================\n",
    "# Feature Engineering\n",
    "# ==================================\n",
    "def create_features(df):\n",
    "    df['CAN_ID_numeric'] = df['CAN_ID_hex'].apply(lambda x: int(str(x), 16) if pd.notna(x) else 0)\n",
    "    df['Data_clean'] = df['Data_hex'].astype(str).str.replace(' ', '').fillna('00000000')\n",
    "\n",
    "    for i in range(8):\n",
    "        df[f'Byte_{i}'] = df['Data_clean'].apply(\n",
    "            lambda x: int(x[i*2:(i+1)*2], 16) if len(x) > i*2+1 else 0\n",
    "        )\n",
    "\n",
    "    byte_cols = [f'Byte_{i}' for i in range(8)]\n",
    "    df['Data_mean'] = df[byte_cols].mean(axis=1)\n",
    "    df['Data_std'] = df[byte_cols].std(axis=1).fillna(0)\n",
    "    df['Data_sum'] = df[byte_cols].sum(axis=1)\n",
    "\n",
    "    if 'DLC' in df.columns:\n",
    "        df['DLC_cat'] = LabelEncoder().fit_transform(df['DLC'].astype(str))\n",
    "    else:\n",
    "        df['DLC_cat'] = 0\n",
    "\n",
    "    df['CAN_Priority'] = pd.cut(df['CAN_ID_numeric'],\n",
    "                                bins=[-1, 255, 1023, np.inf],\n",
    "                                labels=[0, 1, 2]).astype(int)\n",
    "    return df\n",
    "\n",
    "# ==================================\n",
    "# Dataset Class\n",
    "# ==================================\n",
    "class CANDataset(Dataset):\n",
    "    def __init__(self, df, features, labels=None):\n",
    "        self.X = torch.tensor(df[features].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(labels.values, dtype=torch.long) if labels is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "# ==================================\n",
    "# ResNet for Tabular Data\n",
    "# ==================================\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_features, in_features)\n",
    "        self.bn2 = nn.BatchNorm1d(in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.fc1(x)))\n",
    "        out = self.bn2(self.fc2(out))\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNetTabular(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2, num_blocks=3, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.blocks = nn.Sequential(*[BasicBlock(hidden_dim, hidden_dim) for _ in range(num_blocks)])\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.input_layer(x)))\n",
    "        x = self.blocks(x)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "# ==================================\n",
    "# Training Function with Class Weights\n",
    "# ==================================\n",
    "def train_resnet(train_loader, val_loader, input_dim, epochs=30, lr=1e-3, device=\"cuda\"):\n",
    "    model = ResNetTabular(input_dim=input_dim).to(device)\n",
    "\n",
    "    # Compute class weights\n",
    "    all_labels = []\n",
    "    for _, y_batch in train_loader:\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "    class_counts = np.bincount(all_labels)\n",
    "    class_weights = torch.tensor([1.0 / c for c in class_counts], dtype=torch.float32).to(device)\n",
    "    class_weights = class_weights / class_weights.sum()  # normalize\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        all_preds, all_labels_val = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                preds = model(X_val).argmax(1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels_val.extend(y_val.cpu().numpy())\n",
    "        acc = accuracy_score(all_labels_val, all_preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_resnet_model.pth\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Val Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"\\nðŸ“Š Final Validation Report:\")\n",
    "    print(classification_report(all_labels_val, all_preds, digits=4))\n",
    "    return model\n",
    "\n",
    "# ==================================\n",
    "# Main Pipeline\n",
    "# ==================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Training files\n",
    "    train_files = [\n",
    "         \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_1.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_D_2.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_0.csv\",\n",
    "   \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_1.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/0_Training/Pre_train_S_2.csv\"\n",
    "    ]\n",
    "    # Load and concatenate training data\n",
    "    train_df = pd.concat([pd.read_csv(f) for f in train_files], ignore_index=True)\n",
    "    train_df.rename(columns={'Arbitration_ID':'CAN_ID_hex','Data':'Data_hex'}, inplace=True)\n",
    "    train_df = create_features(train_df)\n",
    "\n",
    "    # Binary labels\n",
    "    if 'R' in train_df['Class'].values:\n",
    "        train_df['Binary_Label'] = train_df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "    elif 'Attack' in train_df['Class'].values:\n",
    "        train_df['Binary_Label'] = train_df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "    elif 'SubClass' in train_df.columns:\n",
    "        train_df['Binary_Label'] = train_df['SubClass'].apply(lambda x: 0 if pd.isna(x) or x == 'Normal' else 1)\n",
    "    else:\n",
    "        train_df['Binary_Label'] = np.random.choice([0, 1], size=len(train_df), p=[0.7, 0.3])\n",
    "\n",
    "    features = ['CAN_ID_numeric','Data_mean','Data_std','Data_sum'] + [f'Byte_{i}' for i in range(8)] + ['DLC_cat','CAN_Priority']\n",
    "\n",
    "    # Train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_df[features], train_df['Binary_Label'],\n",
    "        test_size=0.2, stratify=train_df['Binary_Label'], random_state=42\n",
    "    )\n",
    "\n",
    "    train_ds = CANDataset(X_train.join(y_train), features, y_train)\n",
    "    val_ds = CANDataset(X_val.join(y_val), features, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=128)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = train_resnet(train_loader, val_loader, input_dim=len(features), device=device)\n",
    "\n",
    "    # ==================================\n",
    "    # Test Files\n",
    "    # ==================================\n",
    "    test_files = [\n",
    "       \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/1_Submission/Pre_submit_D.csv\",\n",
    "    \"/Users/bodapati/Downloads/Car_Hacking_Challenge_Dataset_rev20Mar2021/0_Preliminary/1_Submission/Pre_submit_S.csv\"\n",
    "]\n",
    "\n",
    "    test_df = pd.concat([pd.read_csv(f) for f in test_files], ignore_index=True)\n",
    "    test_df.rename(columns={'Arbitration_ID':'CAN_ID_hex','Data':'Data_hex'}, inplace=True)\n",
    "    test_df = create_features(test_df)\n",
    "\n",
    "    # Binary labels if exist\n",
    "    if 'Class' in test_df.columns:\n",
    "        if 'R' in test_df['Class'].values:\n",
    "            test_df['Binary_Label'] = test_df['Class'].apply(lambda x: 1 if x == 'R' else 0)\n",
    "        elif 'Attack' in test_df['Class'].values:\n",
    "            test_df['Binary_Label'] = test_df['Class'].apply(lambda x: 1 if x == 'Attack' else 0)\n",
    "        elif 'SubClass' in test_df.columns:\n",
    "            test_df['Binary_Label'] = test_df['SubClass'].apply(lambda x: 0 if pd.isna(x) or x == 'Normal' else 1)\n",
    "        else:\n",
    "            test_df['Binary_Label'] = np.random.choice([0, 1], size=len(test_df), p=[0.7, 0.3])\n",
    "    else:\n",
    "        test_df['Binary_Label'] = np.zeros(len(test_df))  # dummy labels\n",
    "\n",
    "    test_ds = CANDataset(test_df, features, test_df['Binary_Label'])\n",
    "    test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "    # ==================================\n",
    "    # Evaluate on Test Data\n",
    "    # ==================================\n",
    "    model.eval()\n",
    "    all_preds, all_labels_test = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            preds = model(X_test).argmax(1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels_test.extend(y_test.cpu().numpy())\n",
    "\n",
    "    print(\"\\nðŸ“Š Test Set Report:\")\n",
    "    print(classification_report(all_labels_test, all_preds, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
